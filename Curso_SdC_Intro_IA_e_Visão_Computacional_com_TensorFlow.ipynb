{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mNm4ZVS8Y5W240LAC77S37W0I8KfVHYg",
      "authorship_tag": "ABX9TyN5ZYZ55YeyDMeu1iIKoH10",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byteLm/Intro_Visao-Computacional_e_IA_com_TF/blob/main/Curso_SdC_Intro_IA_e_Vis%C3%A3o_Computacional_com_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introdução à Inteligência Artificial e Visão Computacional com TensorFlow\n",
        "---\n",
        "*Inteligência artificial é uma das áreas mais promissoras na atualidade. Sua base interdisciplinar, bem como sua capacidade multiagente e multiambiente possibilitam aplicações nas mais diversas áreas - trata-se de um novo paradigma para solução de problemas diversos, seja para prever valores de residências, seja para detectar e descriminar objetos em cenas sem definição algorítmica direta.*\n",
        "\n",
        "*Este minicurso tem como objetivo introduzir os principais conceitos referentes a área de Inteligência Artificial, bem como aprofundar conceitos de Visão Computacional, perpassando pelo desenvolvimento de um classificador de dígitos e roupas, e posteriormente efetuando a detecção destes em cenas, utilizando Redes Neurais Artificiais (ANN) e TensorFlow/Keras API.*\n",
        "\n",
        "- *Consulte o material completo em:*"
      ],
      "metadata": {
        "id": "p89JoRwKqyyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "*GitHub/Slides"
      ],
      "metadata": {
        "id": "br3LvfUwu5p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visão Computacional\n",
        "Quando tratamos de percepção, sem dúvidas um dos sentidos mais importantes é a visão. Tarefas que para o ser humano são triviais, como distinção entre dois tipos de objetos, ou determinar a localização destes, algoriticamente é uma tarefa bem complicada. Afinal, como descrever limiares do que é ou não é uma cadeira?\n",
        "\n",
        "\n",
        "\n",
        "Visão Computacional pode ser considerada a junção de Processamento Digital de Imagens (PDI) e Inteligência Artificial. Em seu escopo, trataremos de duas clássicas problemáticas: *classificação* e *detecção* de objetos em cenas."
      ],
      "metadata": {
        "id": "ipLhep-dsOqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relação entre X e Y\n",
        "Tradicionalmente, quando desejamos resolver um problema utilizando programação, pensamos em algoritmos que levem a uma solução. De exemplo, podemos descrever funções do tipo:\n"
      ],
      "metadata": {
        "id": "7TQr0J6PvwCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Somar(a, b):\n",
        "    return a + b"
      ],
      "metadata": {
        "id": "vFnKF4bbepi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "O mesmo vale para \"funções mais complexas\", isto é, para relacionar dois valores (X, Y), definiríamos previamente \"a lei de funcionamento\", e por fim obteríamos o resultado:"
      ],
      "metadata": {
        "id": "C7NP83eCewsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def VezesDoisMenosTres(a):\n",
        "    return (2*a)-3"
      ],
      "metadata": {
        "id": "s3zDpJBcezkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Quando tratamos de apredizagem de máquina, o paradigma para solução é diferente. Enquanto tradicionalmente colocaríamos as regras para saída, iremos \"mostrar exemplos\" e deixar o algoritmo criá-la. Simples, não?\n",
        "\n",
        "Para a função VezesDoisMenosTres criada anteriormente, poderíamos definir os seguintes dados como exemplo:"
      ],
      "metadata": {
        "id": "XyXC_7FXe3vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "Xs = np.array([1, 2, 3, 4], dtype = float)\n",
        "Ys = np.array([-1, 1, 3, 5], dtype = float)"
      ],
      "metadata": {
        "id": "jNHm_BLxe62Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para encontrar a relação entre eles, iremos utilizar apenas uma camada, contendo apenas um neurônio, que recebe apenas um valor X como entrada:"
      ],
      "metadata": {
        "id": "8mM5LkhKe_R2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando bibliotecas\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "kF_Lyn06-hq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando modelo\n",
        "model = keras.Sequential(keras.layers.Dense(units=1, input_shape=[1]))\n",
        "\n",
        "# Compilando\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "# Realizando treinamento\n",
        "model.fit(Xs, Ys, epochs = 2000)"
      ],
      "metadata": {
        "id": "NCx-RYnufr6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predição\n",
        "model.predict([10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1v2h29UhdcF",
        "outputId": "97e1b87e-2cca-44a7-a386-bec61f0da572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 55ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16.977518]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Note que no exemplo acima, ao compilar o modelo, utilizamos a função de perca 'mean_squared_error' (MSE), bem como o otimizador 'Gradiente Descendente Estocástico' (SGD)."
      ],
      "metadata": {
        "id": "owVgRfUMkIVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sobre funções de custo, algumas das mais comuns incluem:\n",
        "\n",
        "* Erro Quadrático Médio (MSE): é uma das funções de custo mais comuns e é usada em problemas de regressão. Ela calcula a média dos erros quadráticos entre as previsões do modelo e os valores alvo.\n",
        "\n",
        "* Entropia Cruzada (CE): função de custo comumente usada em problemas de classificação. Ela calcula a distância entre a distribuição de probabilidade prevista pelo modelo e a distribuição de probabilidade real.\n",
        "\n",
        "* Função Hinge: usada em problemas de classificação binária e multi-classe e mede o erro no caso de previsões incorretas.\n",
        "\n",
        "* Função Logarítmica: usada em problemas de classificação binária e calcula o logaritmo da diferença entre a previsão do modelo e o valor real.\n",
        "\n",
        "Cada uma dessas funções de custo tem suas próprias características e limitações e a escolha da função de custo adequada é uma parte importante do projeto de modelos, você pode consultar mais com este link.\n",
        "\n",
        "\n",
        "Sobre otimizadores, eles são usados para atualizar os pesos do nosso modelo durante o treinamento, de forma a minimizar a função de custo. Eles são cruciais para o processo de aprendizagem. São exemplos comuns:\n",
        "\n",
        "* Gradiente Descendente (SGD): é um dos otimizadores mais básicos e consiste em atualizar os pesos do modelo na direção oposta ao gradiente da função de custo.\n",
        "\n",
        "* Gradiente Descendente Estocástico (SGD): é uma versão do SGD que atualiza os pesos a cada amostra de treinamento, em vez de fazê-lo após o processamento de todo o conjunto de dados de treinamento.\n",
        "\n",
        "* Adam (Adaptive Moment Estimation): combina o SGD com a média exponencial dos gradientes anteriores, a fim de melhorar a convergência do treinamento.\n",
        "\n",
        "* Adagrad: ajusta o ritmo de aprendizado individualmente para cada parâmetro, de forma a lidar com features de alta dimensionalidade e de pesos de diferentes magnitude.\n",
        "\n",
        "* RMSProp: é semelhante ao Adagrad, mas tem uma correção de memória para evitar que o ritmo de aprendizado decaia rapidamente."
      ],
      "metadata": {
        "id": "1v1gIQXBfrU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classificando dígitos\n",
        "\n"
      ],
      "metadata": {
        "id": "EsY0Th4xejw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contextualização\n",
        "Em mesmo viés, para classificar imagens é possível utilizar abordagens clássicas de Processamento Digital de Imagens de maneira \"pura\". Por exemplo, é possível classificar se na figura abaixo está contido **um círculo**, apenas utilizando HoG - não de maneira simples, mas possível."
      ],
      "metadata": {
        "id": "iVaFXsoNAkCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "## Carregando imagem 'formas geométricas'\n",
        "path = \"/content/drive/MyDrive/formas-geometricas.png\" # Pode utilizar outras imagens! :)\n",
        "img = cv2.imread(path)\n",
        "plt.imshow(img)\n",
        "\n",
        "# Conversão para escala de cinza\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Aplicação filtro de blur\n",
        "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "# Aplicando detecção de bordas com Canny\n",
        "edges = cv2.Canny(blur, 50, 150, apertureSize=3)\n",
        "\n",
        "# Informa se há circulos\n",
        "circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 20, param1=50, param2=30, minRadius=0, maxRadius=0)\n",
        "if circles is not None:\n",
        "    print(\"Está contido um círculo!\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "Zy1U3stzXoJU",
        "outputId": "6e02a01a-9859-4a61-a347-a0fa09057b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Está contido um círculo!\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todavia, essa abordagem não funciona ainda para o problema de classificação de dígitos. Visualmente, como podemos diferenciar o 7 e o 2 contido abaixo? Descrever algoritmicamente, com alta modularidade para casos de testes, é *complicado*."
      ],
      "metadata": {
        "id": "dIev_E7XYZ6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando o dataset mnist do TensorFlow\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Plotando dois exemplos\n",
        "fig, axs = plt.subplots(1,2, figsize=(20, 20))\n",
        "axs[0].imshow(test_images[0]) # 7\n",
        "axs[1].imshow(test_images[1]) # 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "YPGMX4-o-Oih",
        "outputId": "1efd9fcc-39ff-4db2-834b-e2d93cb64f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-fa5cdf1dbecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Carregando o dataset mnist do TensorFlow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Plotando dois exemplos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para tanto, utilizaremos a mesma abordagem apresentada na relação X/Y, com um pouco mais de complexidade."
      ],
      "metadata": {
        "id": "McvStCV2AT4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explicando o MNIST"
      ],
      "metadata": {
        "id": "VA8UGd9fA2LD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST é um conjunto de dados de aprendizado de máquina popular, composto por 70.000 imagens em escala de cinza de dígitos manuscritos (de 0 a 9). É amplamente utilizado como um benchmark para avaliar o desempenho de modelos de visão computacional, bem como é problema clássico do campo.\n",
        "\n",
        "\n",
        "Ainda que o conjunto de dados MNIST seja simples, é possível apresentar conceitos complexos utilizando este; além do mais, o conjunto está integrado com o Keras/Tensorflow, tendo assim o seu acesso facilitado."
      ],
      "metadata": {
        "id": "eP2GSFfUEz8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fb1O-IlhGfVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Carregando e pré-processando MNIST\n",
        "\n"
      ],
      "metadata": {
        "id": "NKOY8sE2GiLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma etapa importante, se não a mais importante, antes de efetivamente processarmos informações/dados por uma rede neural, é pré-processarmos os dados. Essa tarefa é importante por vários fatores, podemos citar:\n",
        "\n",
        "- Evitar erros como 'estouro' da representação de ponto flutuante\n",
        "- Agilizar o treinamento diminuindo a amplitude dos pesos\n",
        "- Evitar viés do modelo\n",
        "- Remover outliers ou ruídos\n",
        "\n",
        "Sendo assim, não faremos diferente com o MNIST:"
      ],
      "metadata": {
        "id": "1JGGTqzOGnQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Inicialmente, iremos carregar o tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "## Carregando o dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "#print(\"\\nAntes do processamento:\\n\\n\" + str(test_images[0]))"
      ],
      "metadata": {
        "id": "zNUPcNguGhWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Iremos normalizar os dados para diminuir a amplitude dos pesos\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "#print(\"\\nApós o processamento:\\n\\n\" + str(test_images[0]))"
      ],
      "metadata": {
        "id": "xYssvxMwJplN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Criando e compilando o modelo\n"
      ],
      "metadata": {
        "id": "6rx-GmUeKWvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando modelo de classificação\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), # Transforma a imagem 28x28 em um array 1D\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)]) # Transforma a saída anterior em probabilidade multiclasse\n",
        "\n",
        "# Compilando modelo\n",
        "model.compile(optimizer = tf.optimizers.Adam(), # A ideia básica: Adam calcula os momentos dos gradientes (isto é, a média e a variação) dos parâmetros do modelo, e utilizá-los para ajustar os pesos de maneira mais precisa.\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ITwnBYydKSK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Treinando o modelo"
      ],
      "metadata": {
        "id": "2QavKXmINSHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_images, training_labels, epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4UwNnImNRtl",
        "outputId": "ae630597-b734-4b2a-ce76-fa17ec33cf4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0033 - accuracy: 0.9991\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0032 - accuracy: 0.9989\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0025 - accuracy: 0.9992\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0030 - accuracy: 0.9991\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9992\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0021 - accuracy: 0.9993\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0012 - accuracy: 0.9996\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0026 - accuracy: 0.9993\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 0.9993\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0025 - accuracy: 0.9992\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9997\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0030 - accuracy: 0.9993\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0036 - accuracy: 0.9989\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 0.9994\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0028 - accuracy: 0.9991\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0014 - accuracy: 0.9995\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0031 - accuracy: 0.9988\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9996\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 0.9993\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0015 - accuracy: 0.9995\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0031 - accuracy: 0.9989\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9998\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 0.9991\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0019 - accuracy: 0.9994\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 0.9994\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9994\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0022 - accuracy: 0.9992\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9996\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0031 - accuracy: 0.9993\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0017 - accuracy: 0.9994\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9995\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 0.9997\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0024 - accuracy: 0.9994\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0011 - accuracy: 0.9995\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0025 - accuracy: 0.9992\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0013 - accuracy: 0.9995\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.4433e-04 - accuracy: 0.9999\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.0284e-05 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.5554e-06 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.2848e-06 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 7.9689e-07 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 5.0997e-07 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45467c43a0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haC5gDDBNOoG",
        "outputId": "a5389e90-787b-4122-c7a1-00093f47c9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2060 - accuracy: 0.9815\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20595304667949677, 0.9815000295639038]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3tAQJ1oMB1g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}